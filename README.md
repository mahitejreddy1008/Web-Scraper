# PYTHON-PROJECT
Web Scraping
Web scraping is a term used to describe the use of a program or algorithm to extract and
process large amounts of data from the web. Web scraping is used to collect large
information from websites. The data on the websites are unstructured. Web scraping helps
collect these unstructured data and store it in a structured form.

The Internet hosts perhaps the greatest source of information—and misinformation—on the
planet. Many disciplines, such as data science, business intelligence, and investigative
reporting, can benefit enormously from collecting and analyzing data from websites.

In this project, we have decided to scrape data from an e-commerce website. The main
motive of scraping an e-commerce website is Product Comparison. Using their HTML tags,
products can be compared for their prices, specifications, ratings and reviews. Since this data
is mainly unstructured, using a web scraping tool will be very helpful to get this data in an
organised manner. This makes our job much simpler and easier!

Some python libraries that will be helpful for implementing this project are:

• Requests: This critical library is needed to actually get the data from the web server
onto your machine, and it contains some additional features like caching too.
The requests module allows you to send HTTP requests using Python. The HTTP
request returns a Response Object with all the response data (content, encoding,
status, etc).

• Beautiful Soup: Beautiful Soup is a library that makes it easy to scrape information
from web pages. It sits atop an HTML or XML parser, providing Pythonic idioms for
iterating, searching, and modifying the parse tree.

• Selenium: The selenium package is used to automate web browser interaction from
Python. Selenium is a powerful tool for controlling web browsers through programs
and performing browser automation. It is functional for all browsers, works on all
major OS.

• Urllib: Urllib module is the URL handling module for python. It is used to fetch
URLs (Uniform Resource Locators). It uses the urlopen function and is able to fetch
URLs using a variety of different protocols.
